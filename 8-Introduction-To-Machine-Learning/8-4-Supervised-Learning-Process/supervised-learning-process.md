Sure! Hereâ€™s the exact transcript organized into sections according to topics on the supervised learning process:

### Introduction to Supervised Learning
Welcome back everyone to this lecture on the Supervised Machine Learning Process. The first half of machine learning algorithms we're going to be learning about fall under the supervised learning umbrella. So what we wanna do is really focus on the philosophy and details behind supervised learning, including things in the process like the train/test split and performance validation, as well as hyper parameters adjustments. So what we're gonna do here is just see how supervised learning fits into the overall machine learning pathway and the specific details behind supervised learning. That way, when we're actually coding this out with things like scikit-learn and Python, we don't just see these ideas for the first time. Instead, we have a philosophical understanding of why we're actually performing the tasks in Python.

### Machine Learning Pathway
So as I mentioned, let's take a look at this within the entire machine learning pathway. We know that we're going to collect and store data from the real world. Then we can clean and organize that data, and then we can perform exploratory data analysis, things like statistical analysis or just visualizations. Then if we want to move beyond data analysis and actually create a data product, that's where we're going to need machine learning models, for supervised learning, where we're predicting an outcome or unsupervised learning, where we're discovering patterns in data. And as far as Python is concerned, we know for the data analysis portion, we have Jupiter, NumPy, Pandas, Matplotlib, and Seaborn. Then when it comes to the machine learning models section, we actually have this very large and powerful library called scikit-learn available to us. And so what we wanna do right now is focus on what's actually going on when we talk about supervised learning, predicting an outcome.

### Overview of Supervised Learning Process
This machine learning model's block in the entire pathway actually contains many substeps within it. So what we're gonna do is really focus on what's happening when we talk about supervised learning, and we're gonna call this the machine learning process for supervised learning tasks. Later on in the course, we'll go over the machine learning process for unsupervised learning, but the first half of algorithms we encounter are all falling under supervised learning. So let's take a deeper dive by taking a look at the example problem that we keep referring to, which is trying to predict the price a house should sell at.

### Data Collection and Organization
So what we're gonna need to do is start with collecting and organizing a dataset based off history. So that means we're going to take a look around our neighborhood at prices that we know houses have been sold at in the past, and we take some note of their features like their area, bedrooms, bathrooms, and then the historical price that they sold at. Note here is that we have a historical labeled dataset on previously sold houses. And then what we're going to do is try to create a data product that can help us with the task of predicting what price a house should sell it. So at the end of the day, if a new house comes onto the market, we wanna know if we know the area, bedrooms and bathrooms of the house, what price should I list it at based off what I know about historically sold housing?

### Defining Inputs and Outputs
So for a data product, you always have some sort of input and output. In this case, we have the input of house features and the output of hopefully the predicted selling price. So we're using historical labeled data to predict a future outcome or result, which essentially is the definition of supervised learning. So let's take a deeper dive into all the subsets that are gonna happen within this supervised learning process on predicting the price a house should sell at.

### Separating Features and Labels
So we already know that we have that data. We run around and we grab that historical data on the features of a house and then the predicted price. The next step for supervised machine learning process is to separate that data into features and label. And you'll notice here that I said X to Features and y to Label. Don't worry too much about that notation right now. Later on, we'll discover as we essentially map out this process to mathematical matrix notation that we typically label Features as the X matrix and the Label as the Y. But for right now, let's just go and have an overview of what are features and what is the label.

### Understanding Features and Labels
So we already know we have this entire dataset, and what we need to do is understand the label. The label is just a term for what are we trying to predict. And in this case, we know we're trying to predict the price of a future house, which means the price column is going to be the label itself. Then we know features are the known characteristics or components in the data that we're predicting the label from. In that case, it's all the features of the house, such as the area, the number of bedrooms and number of bathrooms. And now, we've taken our complete dataset and we've assigned the features that we're predicting from and the label, what we're trying to predict. And so we can notice here, we have labeled historical data. We know all the features that correspond to the label or price that house sold at.

### Train/Test Split Explanation
Now, the next step that is absolutely critical to the supervised machine learning process is this training/test split. So what we end up doing is once we've identified features and label, we split the data into a training set and a test set. Keep in mind, later on in the course, we're gonna discuss more advanced methods of this, generally called cross validation, and we'll also talk about holdout sets. But for right now, let's take the simplest approach, which is splitting into two sets, a training set, and a test set. 

### Importance of the Split
So the obvious question then is why are we performing this split and how do I decide how to split up this data? Well, in my personal opinion, the easiest way to understand this is by taking a step back from judging an algorithm and deciding how would you actually judge a human's performance on choosing a selling or listing price for a new house on the market. So let's imagine you have a friend who is a human realtor. Well, how would you judge a human realtor's performance if you had an existing dataset and a new house that you wanted to put on the market? So what you could do is you ask your human realtor to take a look at the entire historical dataset. You give them the features and then the price that these houses have sold at in the past, and you want their help for choosing the price for a new house on the market.

### Evaluating Human Performance
So after giving her the features of the house, we wanna ask her to predict that selling price, but the problem is how do we actually measure how accurate her prediction is and what house should we choose to test her on? Unfortunately, we can't actually judge her based off the brand new house because it hasn't sold yet. We don't actually know what the correct true selling price is, and it's not gonna be very useful to us if we judge her performance after we sell this new house, because, then what was the point of actually having her help to begin with? 

### Need for Train/Test Split
So what we wanna do is be able to judge her performance before we decide on a price for that historical house. Now, the problem also occurs is that we can't really judge her on the data that she's already seen because in theory, she could have just memorized the entire dataset and thus have perfect accuracy when we're recalling what the price of a house sold at. And this is where the need for the train/test split comes into play. Basically, the idea is we want to be able to fairly evaluate the performance of both our human realtor or later on, our machine learning algorithm.

### Performing the Train/Test Split
So let's think about how we're actually performing this train/test split. So we already organized the data into features that we're calling X and the label that we're calling Y. And what we're going to do is split this into a training set and a test set. This way, we can feed the training set to our human realtor or our algorithm, have them learn off the training set and then evaluate them off data they haven't seen before, which will be the test set. So notice here that the training set and test set both grab the features and the labels, and typically, you decide on some sort of percentage split. And it's really common to have most of the data be falling under the training set and have some of the data fall under the test set, such as 70% for training and 30% for test.

### Components of the Split
But we'll discuss in much more detail how to decide on those splits, as well as more advanced methods of performing these splits. But the main idea is we're gonna show the algorithm some training data and then evaluate the performance on some test data. Keep in mind that if we really thought about this, we actually have four components. We have the features for training and the label for training. That is, X train and Y train. And then we also have the features for testing X test and the label for testing, Y test. So keep in mind, later on, when we're coding this out with Python, we'll actually see this labeled as four separate components. Even though technically, we only have one training set and one test set, we could separate this out based off the features. So we have X train, Y train, and X test, Y test. And this further separation into four components actually becomes important later on when we evaluate the performance.

### Testing Human Performance
So let's go back to fairly testing our human realtor on this. We take the training test as well as the test set, and then what we're going to do is we're only going to let the human realtor study and learn on the training set. We give them access to both the